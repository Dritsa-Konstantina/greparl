{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36209a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:52:53.303430\n",
      "read input file\n",
      "cleaning speeches...\n",
      "speeches cleaned\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from collections import Counter\n",
    "import operator\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import tqdm.notebook as tq\n",
    "\n",
    "print(datetime.datetime.now().time())\n",
    "\n",
    "# \\u00b7 is middle dot\n",
    "# \\u0387 is Greek ano teleia\n",
    "punct_regex = re.compile(r\"([?.!,;\\u00b7\\u0387])\")\n",
    "\n",
    "def str_clean(s):\n",
    "   normalized = ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "   separate_punct = re.sub(punct_regex, r\" \\1 \", normalized)\n",
    "   collapse_spaces  = re.sub(r'\\s+', \" \", separate_punct)\n",
    "   lc = collapse_spaces.lower()\n",
    "   return lc\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "\n",
    "df = pd.read_csv('../out_files/tell_all_cleaned.csv') #, nrows=10\n",
    "print('read input file')\n",
    "df = df[df['speech'].notna()]\n",
    "print('cleaning speeches...')\n",
    "df.speech = df.speech.apply(lambda x: str_clean(x))\n",
    "print('speeches cleaned')\n",
    "\n",
    "df.speech = df.speech.apply(lambda x: x.replace(\".\", \" \"))\n",
    "df.sitting_date = pd.to_datetime(df.sitting_date, format=\"%d/%m/%Y\")\n",
    "\n",
    "#New column year\n",
    "df['year'] = df['sitting_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d85a16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PERyear_df = df.copy().groupby(df.year)['speech'].apply(''.join).reset_index() #concat sentences, each last sentence for each speech did not have dot so add one.\n",
    "\n",
    "mask1 = (PERyear_df['year'] >= 1997) & (PERyear_df['year'] <= 2007)\n",
    "corpus_before = '\\n'.join([text for text in PERyear_df.loc[mask1].speech])\n",
    "\n",
    "mask2 = (PERyear_df['year'] >= 2008) & (PERyear_df['year'] <= 2018)\n",
    "corpus_after = '\\n'.join([text for text in PERyear_df.loc[mask2].speech])\n",
    "\n",
    "crisis_dichotomy_df = pd.DataFrame(data=[['1997_2007', corpus_before],\n",
    "                                         ['2008_2018', corpus_after]],\n",
    "                                   columns = ['period', 'speech'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2c0094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997_2007\n",
      "finished counting\n",
      "total number of tokens: 59484378\n",
      "Removed entries with one character.\n",
      "2008_2018\n",
      "finished counting\n",
      "total number of tokens: 72465035\n",
      "Removed entries with one character.\n",
      "19:58:09.130683\n"
     ]
    }
   ],
   "source": [
    "\n",
    "periods = crisis_dichotomy_df.period.to_list()\n",
    "\n",
    "\n",
    "for period in periods:\n",
    "    print(period)\n",
    "    subdf = crisis_dichotomy_df.loc[(crisis_dichotomy_df.period==period)]\n",
    "\n",
    "    tell_all = subdf.speech.iloc[0].lower()\n",
    "\n",
    "    # tell_all = re.sub(\"\\d+\", \"\", tell_all)\n",
    "    tell_all = re.sub(\"\\s\\s+\" , ' ', tell_all)\n",
    "\n",
    "    freqs = Counter()\n",
    "    subdf.speech.apply(lambda x: freqs.update(x.split()))\n",
    "    print('finished counting')\n",
    "    total_number = sum(freqs.values())\n",
    "    print('total number of tokens:', total_number)\n",
    "\n",
    "    freqs_df = pd.DataFrame.from_dict(freqs, orient='index',\n",
    "                                      columns=['frequency'])\n",
    "    freqs_df = freqs_df.reset_index()\n",
    "\n",
    "    freqs_df = freqs_df.rename(columns={'index': 'word'})\n",
    "    mask = (freqs_df['word'].str.len() > 1)\n",
    "    freqs_df = freqs_df.loc[mask]\n",
    "    print('Removed entries with one character.')\n",
    "\n",
    "    freqs_df = freqs_df.sort_values('frequency').reset_index(drop=True)\n",
    "\n",
    "    freqs_df['percentage'] = freqs_df['frequency'] / total_number\n",
    "\n",
    "    freqs_df.to_csv('../out_files/freqs_for_semantic_shift_cleaned_data_period'+str(period)+'.csv', index=False)\n",
    "\n",
    "print(datetime.datetime.now().time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a4107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".parl_env",
   "language": "python",
   "name": ".parl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
